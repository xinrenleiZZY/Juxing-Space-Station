import os
import time
import pandas as pd
import logging
from config.settings import PROCESSED_DATA_DIR
from src.utils.logger import setup_logger


def data_sync():
    """åŒæ­¥data/processedçš„CSVæ–‡ä»¶åˆ°lstm_analysis/data_preparation
    
    åŠŸèƒ½ï¼š
    - è¯»å–data/processedç›®å½•ä¸‹çš„æ‰€æœ‰CSVæ–‡ä»¶
    - åˆå¹¶è¿™äº›CSVæ–‡ä»¶
    - ä¿å­˜ä¸ºæ—¶é—´æˆ³_LstmData.csvæ ¼å¼åˆ°lstm_analysis/data_preparationç›®å½•
    """
    logger = setup_logger("data_sync")
    logger.info("å¼€å§‹æ‰§è¡Œæ•°æ®åŒæ­¥æ“ä½œ")
    
    print("ğŸ”„ å¼€å§‹æ‰§è¡Œæ•°æ®åŒæ­¥æ“ä½œ...")
    print("==============================================")
    
    try:
        # è·å–processedç›®å½•ä¸‹çš„æ‰€æœ‰CSVæ–‡ä»¶
        processed_dir = PROCESSED_DATA_DIR
        csv_files = [f for f in os.listdir(processed_dir) if f.lower().endswith('.csv')]
        
        if not csv_files:
            logger.warning("æ²¡æœ‰æ‰¾åˆ°éœ€è¦åŒæ­¥çš„CSVæ–‡ä»¶")
            print("âš ï¸  æ²¡æœ‰æ‰¾åˆ°éœ€è¦åŒæ­¥çš„CSVæ–‡ä»¶")
            return
        
        logger.info(f"å‘ç° {len(csv_files)} ä¸ªCSVæ–‡ä»¶éœ€è¦åŒæ­¥")
        print(f"ğŸ“ å‘ç° {len(csv_files)} ä¸ªCSVæ–‡ä»¶éœ€è¦åŒæ­¥")
        
        # åˆå¹¶æ‰€æœ‰CSVæ–‡ä»¶
        all_data = []
        for file_name in csv_files:
            file_path = os.path.join(processed_dir, file_name)
            try:
                logger.info(f"è¯»å–æ–‡ä»¶ï¼š{file_path}")
                df = pd.read_csv(file_path, encoding='utf-8-sig')
                all_data.append(df)
                print(f"âœ… è¯»å–æˆåŠŸï¼š{file_name}")
            except Exception as e:
                logger.error(f"è¯»å–æ–‡ä»¶å¤±è´¥ï¼š{file_path} -> {e}")
                print(f"âŒ è¯»å–æ–‡ä»¶å¤±è´¥ï¼š{file_name} -> {e}")
        
        if not all_data:
            logger.error("æ²¡æœ‰æˆåŠŸè¯»å–ä»»ä½•CSVæ–‡ä»¶")
            print("âŒ æ²¡æœ‰æˆåŠŸè¯»å–ä»»ä½•CSVæ–‡ä»¶")
            return
        
        # åˆå¹¶æ•°æ®
        merged_data = pd.concat(all_data, ignore_index=True)
        logger.info(f"åˆå¹¶å®Œæˆï¼Œå…± {len(merged_data)} è¡Œæ•°æ®")
        print(f"ğŸ“Š åˆå¹¶å®Œæˆï¼Œå…± {len(merged_data)} è¡Œæ•°æ®")
        
        # åˆ›å»ºè¾“å‡ºè·¯å¾„ï¼ˆé¡¹ç›®æ ¹ç›®å½•ä¸‹çš„lstm_analysisï¼‰
        project_root = os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
        output_dir = os.path.join(project_root, "lstm_analysis", "data_preparation")
        os.makedirs(output_dir, exist_ok=True)
        
        # ç”Ÿæˆæ—¶é—´æˆ³æ–‡ä»¶å
        timestamp = time.strftime("%Y%m%d_%H%M%S")
        output_file = f"{timestamp}_LstmData.csv"
        output_path = os.path.join(output_dir, output_file)
        
        # ä¿å­˜æ–‡ä»¶
        merged_data.to_csv(output_path, index=False, encoding='utf-8-sig')
        logger.info(f"æ•°æ®å·²ä¿å­˜åˆ°ï¼š{output_path}")
        print(f"âœ… æ•°æ®å·²ä¿å­˜åˆ°ï¼š{output_path}")
        
        logger.info("æ•°æ®åŒæ­¥æ“ä½œå®Œæˆ")
        print("==============================================")
        print("âœ… æ•°æ®åŒæ­¥æ“ä½œå®Œæˆï¼")
        print("==============================================")
        
    except Exception as e:
        logger.error(f"æ•°æ®åŒæ­¥æ“ä½œå¤±è´¥ï¼š{e}")
        print(f"âŒ æ•°æ®åŒæ­¥æ“ä½œå¤±è´¥ï¼š{e}")


__all__ = ["data_sync"]